import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode, AudioProcessorBase
from langchain.schema import HumanMessage
from ai.graphs.chat_graph import chat_graph
import av
import numpy as np
import tempfile
import os

import wave
import json
import re
from vosk import Model, KaldiRecognizer

# –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ Vosk - –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Å–∫–∞—á–∞–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
MODEL_PATH = "vosk-model-ru-0.22"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –∏–º–µ–Ω–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
def get_short_repo_name(url: str) -> str:
    url = re.sub(r"\.git$", "", url)
    parts = url.split("/")
    return parts[-1] if parts else "unknown"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—É—Ç–∏ –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
def get_vector_db_path():
    if "repositories" in st.session_state and "selected_repo_index" in st.session_state:
        selected_repo = st.session_state["repositories"][st.session_state["selected_repo_index"]]
        short_name = get_short_repo_name(selected_repo["url"])
        return f"storage/{short_name}/vectore_store/"
    elif "selected_repo" in st.session_state and st.session_state["selected_repo"]:
        # –î–ª—è —Å–ª—É—á–∞—è, –∫–æ–≥–¥–∞ –µ—Å—Ç—å selected_repo, –Ω–æ –Ω–µ—Ç repositories
        repo_name = st.session_state["selected_repo"]["repo_name"]
        return f"storage/{repo_name}/vectore_store/"
    else:
        return "storage/default/vectore_store/"

# –ê—É–¥–∏–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –∞—É–¥–∏–æ–∫–∞–¥—Ä–æ–≤
class AudioProcessor(AudioProcessorBase):
    def __init__(self):
        self.frames = []
        self.recording = True
        self.sample_rate = None
        
    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
        if self.recording:
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∫–∞–¥—Ä–µ
            if self.sample_rate is None:
                self.sample_rate = frame.sample_rate
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ
            self.frames.append(frame.to_ndarray())
        return frame

def download_vosk_model():
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ Vosk, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
    if not os.path.exists(MODEL_PATH):
        st.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏. –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...")
        import urllib.request
        import zipfile
        
        # URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –Ω–µ–±–æ–ª—å—à–æ–π —Ä—É—Å—Å–∫–æ–π –º–æ–¥–µ–ª–∏ (~45 –ú–ë)
        model_url = "https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip"
        zip_path = "vosk-model.zip"
        
        # –°–∫–∞—á–∏–≤–∞–µ–º –∞—Ä—Ö–∏–≤ —Å –º–æ–¥–µ–ª—å—é
        urllib.request.urlretrieve(model_url, zip_path)
        
        # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –∞—Ä—Ö–∏–≤
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall("./")
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –ø–∞–ø–∫—É —Å –º–æ–¥–µ–ª—å—é
        os.rename("vosk-model-small-ru-0.22", MODEL_PATH)
        
        # –£–¥–∞–ª—è–µ–º –∞—Ä—Ö–∏–≤
        os.remove(zip_path)
        
        st.success("–ú–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Vosk
def process_audio_frames(frames, sample_rate=16000):
    if not frames or len(frames) == 0:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –∞—É–¥–∏–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏
        if not os.path.exists(MODEL_PATH):
            download_vosk_model()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        model = Model(MODEL_PATH)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å
        rec = KaldiRecognizer(model, sample_rate)
        rec.SetWords(True)  # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∞—É–¥–∏–æ–∫–∞–¥—Ä—ã
        audio_data = np.concatenate(frames, axis=0)
        audio_data = audio_data.flatten().astype(np.int16)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π WAV —Ñ–∞–π–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
            filepath = temp_file.name
            
        with wave.open(filepath, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)  # 16 bits
            wf.setframerate(sample_rate)
            wf.writeframes(audio_data.tobytes())
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ–º
        with wave.open(filepath, 'rb') as wf:
            # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∞–º–∏
            while True:
                data = wf.readframes(4000)
                if len(data) == 0:
                    break
                
                # –ü–æ–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å
                rec.AcceptWaveform(data)
            
            # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result_json = rec.FinalResult()
            result = json.loads(result_json)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            recognized_text = result.get("text", "")
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        os.unlink(filepath)
        
        if not recognized_text:
            return "–†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç—å —á–µ—Ç—á–µ."
        
        return recognized_text
        
    except Exception as e:
        return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ: {str(e)}"

def show_chat_page():
    st.title("–ß–∞—Ç –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—é")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–∏
    if "selected_repo" not in st.session_state:
        st.session_state.selected_repo = None
    if "chat1_messages" not in st.session_state:
        st.session_state.chat1_messages = [
            {"role": "assistant", "content": "–ü—Ä–∏–≤–µ—Ç! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"}
        ]
    if "voice_chat_active" not in st.session_state:
        st.session_state.voice_chat_active = False
    if "recording" not in st.session_state:
        st.session_state.recording = False
    if "audio_processor" not in st.session_state:
        st.session_state.audio_processor = None
    if "webrtc_ctx" not in st.session_state:
        st.session_state.webrtc_ctx = None
    if "is_playing" not in st.session_state:
        st.session_state.is_playing = False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ Vosk –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    if not os.path.exists(MODEL_PATH):
        with st.sidebar:
            if st.button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏"):
                download_vosk_model()

    if not st.session_state.get("selected_repo"):
        # –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        if "selected_repo" not in st.session_state:
            st.session_state.selected_repo = {"repo_name": "–¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π", "branch": "main"}
        else:
            st.info("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –≤ –±–æ–∫–æ–≤–æ–º –º–µ–Ω—é.")
            return

    st.write(f"–¢–µ–∫—É—â–∏–π —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: **{st.session_state['selected_repo']['repo_name']}**")
    st.write(f"–í–µ—Ç–∫–∞: **{st.session_state['selected_repo']['branch']}**")

    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
    vector_db_path = get_vector_db_path()
    
    with st.sidebar:
        st.subheader("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
        st.info(f"–ü—É—Ç—å –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {vector_db_path}")

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
    for msg in st.session_state.chat1_messages:
        st.chat_message(msg["role"]).write(msg["content"])

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ WebRTC
    def start_webrtc():
        def audio_processor_factory():
            st.session_state.audio_processor = AudioProcessor()
            return st.session_state.audio_processor
        
        webrtc_ctx = webrtc_streamer(
            key="speech_to_text",
            mode=WebRtcMode.SENDONLY,
            audio_processor_factory=audio_processor_factory,
            rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
            media_stream_constraints={"video": False, "audio": True},
        )
        
        return webrtc_ctx

    # –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —á–∞—Ç
    if not st.session_state.voice_chat_active:
        if prompt := st.chat_input(placeholder="–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å"):
            st.session_state.chat1_messages.append({"role": "user", "content": prompt})
            st.chat_message("user").write(prompt)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            process_text_query(prompt, vector_db_path)
            
        # –ö–Ω–æ–ø–∫–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —á–∞—Ç–∞
        if st.button("–ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç"):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —á–∞—Ç–∞
            if not os.path.exists(MODEL_PATH):
                st.warning("–î–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —á–∞—Ç–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –≤ –±–æ–∫–æ–≤–æ–º –º–µ–Ω—é.")
            else:
                st.session_state.voice_chat_active = True
                st.rerun()
    else:
        # –°—Ç–∏–ª–∏ –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        st.markdown(
            """
            <style>
            .circle-container {
                display: flex;
                flex-direction: column;
                align-items: center;
                justify-content: center;
                margin-top: 20px;
                margin-bottom: 20px;
            }
            .circle {
                width: 80px;
                height: 80px;
                border-radius: 50%;
                background: #ff4b4b;
                box-shadow: 0 0 0 rgba(255,75,75,0.7);
                animation: pulse 2s infinite;
                cursor: pointer;
            }
            @keyframes pulse {
                0% { box-shadow: 0 0 0 0 rgba(255,75,75,0.7); }
                70% { box-shadow: 0 0 0 20px rgba(255,75,75,0); }
                100% { box-shadow: 0 0 0 0 rgba(255,75,75,0); }
            }
            .voice-buttons {
                display: flex;
                gap: 15px;
                margin-top: 20px;
                justify-content: center;
            }
            .record-status {
                text-align: center;
                font-weight: bold;
                margin-top: 10px;
            }
            </style>
            """,
            unsafe_allow_html=True
        )

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WebRTC –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        if st.session_state.webrtc_ctx is None:
            st.session_state.webrtc_ctx = start_webrtc()
            
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è WebRTC –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        webrtc_state = st.session_state.webrtc_ctx.state.playing if st.session_state.webrtc_ctx else False
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–ø–∏—Å–∏
        status_container = st.empty()
        if webrtc_state:
            status_container.markdown('<p class="record-status">üî¥ –ò–¥–µ—Ç –∑–∞–ø–∏—Å—å...</p>', unsafe_allow_html=True)
        else:
            status_container.markdown('<p class="record-status">‚ö™ –ó–∞–ø–∏—Å—å –Ω–µ –∞–∫—Ç–∏–≤–Ω–∞</p>', unsafe_allow_html=True)
        
        # –ê–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫—Ä—É–≥ –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞
        st.markdown('<div class="circle-container"><div class="circle"></div></div>', unsafe_allow_html=True)
        
        # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –∫–Ω–æ–ø–æ–∫ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        button_cols = st.columns(3)
        
        with button_cols[0]:
            # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –Ω–∞—á–∞–ª–∞/–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏
            if not st.session_state.recording:
                if st.button("üé§ –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å", use_container_width=True):
                    st.session_state.recording = True
                    # –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º WebRTC, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ
                    if not webrtc_state and st.session_state.webrtc_ctx:
                        st.session_state.webrtc_ctx.state.playing = True
                    st.rerun()
            else:
                if st.button("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å", use_container_width=True):
                    st.session_state.recording = False
                    
                    # –û—Ç–∫–ª—é—á–∞–µ–º WebRTC
                    if webrtc_state and st.session_state.webrtc_ctx:
                        st.session_state.webrtc_ctx.state.playing = False
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
                    if st.session_state.audio_processor and hasattr(st.session_state.audio_processor, "frames") and st.session_state.audio_processor.frames:
                        frames = st.session_state.audio_processor.frames
                        sample_rate = st.session_state.audio_processor.sample_rate or 16000
                        st.session_state.audio_processor.recording = False
                        
                        with st.spinner("–†–∞—Å–ø–æ–∑–Ω–∞—é –≤–∞—à—É —Ä–µ—á—å..."):
                            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                            recognized_text = process_audio_frames(frames, sample_rate)
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —á–∞—Ç
                        st.session_state.chat1_messages.append({"role": "user", "content": recognized_text})
                        st.chat_message("user").write(recognized_text)
                        
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å
                        with st.spinner("–ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç..."):
                            response = process_text_query(recognized_text, vector_db_path)
                        
                        # –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ HTML
                        if response:
                            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏
                            st.markdown(f"""
                            <div id="speech-container">
                                <script>
                                    try {{
                                        // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏
                                        function speakText() {{
                                            const text = {json.dumps(response)};
                                            if ('speechSynthesis' in window) {{
                                                const utterance = new SpeechSynthesisUtterance(text);
                                                utterance.lang = 'ru-RU';
                                                utterance.rate = 1.0;
                                                speechSynthesis.speak(utterance);
                                                console.log("Speaking: " + text);
                                            }} else {{
                                                console.error("Speech synthesis not supported");
                                            }}
                                        }}
                                        
                                        // –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
                                        if (document.readyState === 'complete') {{
                                            speakText();
                                        }} else {{
                                            window.addEventListener('load', speakText);
                                        }}
                                    }} catch (e) {{
                                        console.error("Speech synthesis error:", e);
                                    }}
                                </script>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        # –û—á–∏—â–∞–µ–º –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–µ —Ñ—Ä–µ–π–º—ã
                        st.session_state.audio_processor.frames = []
                    
                    st.rerun()
                        
        with button_cols[1]:
            if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å", use_container_width=True):
                # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º WebRTC –∫–æ–Ω—Ç–µ–∫—Å—Ç
                st.session_state.webrtc_ctx = None
                st.session_state.audio_processor = None
                st.rerun()
            
        with button_cols[2]:
            if st.button("‚úñÔ∏è –í—ã–π—Ç–∏ –∏–∑ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —á–∞—Ç–∞", use_container_width=True):
                end_msg = "–ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç –æ–∫–æ–Ω—á–µ–Ω"
                st.session_state.chat1_messages.append({"role": "assistant", "content": end_msg})
                st.session_state.voice_chat_active = False
                st.session_state.recording = False
                st.session_state.audio_processor = None
                st.session_state.webrtc_ctx = None
                st.rerun()
                
        # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
        st.markdown("""
        ### –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é:
        1. –ù–∞–∂–º–∏—Ç–µ "üé§ –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å" –∏ —Ä–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –≤ –±—Ä–∞—É–∑–µ—Ä–µ
        2. –ì–æ–≤–æ—Ä–∏—Ç–µ –≤ –º–∏–∫—Ä–æ—Ñ–æ–Ω
        3. –ù–∞–∂–º–∏—Ç–µ "‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å" –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞—à–µ–π —Ä–µ—á–∏
        4. –ï—Å–ª–∏ –∑–∞–ø–∏—Å—å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–∞–∂–º–∏—Ç–µ "üîÑ –û–±–Ω–æ–≤–∏—Ç—å"
        """)

def process_text_query(prompt, vector_db_path):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É—è –≥—Ä–∞—Ñ–æ–≤—ã–π —á–∞—Ç"""
    try:
        # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ HumanMessage
        messages = [HumanMessage(content=prompt)]
        
        # –í—ã–∑—ã–≤–∞–µ–º –≥—Ä–∞—Ñ–æ–≤—ã–π —á–∞—Ç
        with st.chat_message("assistant"):
            with st.spinner("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å..."):
                # –í—ã–∑—ã–≤–∞–µ–º –≥—Ä–∞—Ñ–æ–≤—ã–π —á–∞—Ç —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –ø—É—Ç–µ–º –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ
                res = chat_graph.invoke({
                    "messages": messages,
                    "vector_db_path": vector_db_path
                }, config={"configurable": {"thread_id": "default"}})
                
                # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                response = res['messages'][-1].content
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
                st.session_state.chat1_messages.append({"role": "assistant", "content": response})
                st.write(response)
                return response
    except Exception as e:
        error_msg = f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}"
        st.error(error_msg)
        st.session_state.chat1_messages.append({"role": "assistant", "content": error_msg})
        return error_msg